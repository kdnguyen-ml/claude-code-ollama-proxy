# Configure preferences for Ollama
CLAUDE_CODE_PROXY_PORT=8082
PREFERRED_PROVIDER="ollama"
OLLAMA_API_BASE="http://host.docker.internal:11434"
# NOTE: models must have tool use
BIG_MODEL="codellama:34b-instruct"
SMALL_MODEL="codellama:34b-instruct"

# Fallback API keys (not needed for Ollama but good for fallback)
ANTHROPIC_API_KEY=""
OPENAI_API_KEY=""
GEMINI_API_KEY="" 